{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_ExternalLab_Delhi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYk8NG3yOIT9",
        "colab_type": "text"
      },
      "source": [
        "### A MNIST-like fashion product database\n",
        "\n",
        "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFO6PuxzOIT_",
        "colab_type": "text"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efNjNImfOIUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "8bbd7ab6-1ebe-440b-82ea-aa525fca4c1f"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9C4aAIGOIUH",
        "colab_type": "code",
        "outputId": "cddbc40f-1adf-4e16-eaad-12ba5e8e6149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csP4cpJ8MihI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "27f5b92f-d94e-4196-ccb2-d1e7be2d3759"
      },
      "source": [
        "!pip install -U tensorflow==2.0 --quiet"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 86.3MB 119kB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 47.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 23.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 8.5MB/s \n",
            "\u001b[31mERROR: tensorboard 2.0.1 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.7.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcQSOuKdM3rn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3839aea1-c20a-4201-88b9-e5cf9dd88d4e"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcoZBStrOIUQ",
        "colab_type": "text"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA1WsFSeOIUS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1181863b-9da4-426b-8f65-08375657ed74"
      },
      "source": [
        "import keras"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnbx7TyQOIUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "4d2eb343-5b4c-40e2-ad18-9d781e618bce"
      },
      "source": [
        "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 3us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbiHj5YPOIUc",
        "colab_type": "code",
        "outputId": "bb835c77-a978-4fa8-b3d2-261d2620fc2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(testY[0:5])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g8XUDVIObaT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b39d95fe-858c-4e7e-cb07-5c0817c54b5b"
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tcsylw3oOgbh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "45469434-0b21-41cb-a77d-1e029408f836"
      },
      "source": [
        "testX.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfTGy0LSOpRp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e3a2d475-6da6-4f4b-9040-cf838bafde31"
      },
      "source": [
        "testY[0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDAYzkwyOIUj",
        "colab_type": "text"
      },
      "source": [
        "### Convert both training and testing labels into one-hot vectors.\n",
        "\n",
        "**Hint:** check **tf.keras.utils.to_categorical()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBlfYlANOIUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
        "testY = tf.keras.utils.to_categorical(testY, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I46kFuUFO3_9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "16054e41-7624-47a9-c207-0d84a6a193be"
      },
      "source": [
        "testY[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RHV3b9mzOIUq",
        "colab_type": "code",
        "outputId": "357f4ec4-bce2-488e-9c81-62a1c2b0218f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "print(trainY.shape)\n",
        "print('First 5 examples now are: ', trainY[0:5])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "First 5 examples now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwhQ8e7VOIUw",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the data\n",
        "\n",
        "Plot first 10 images in the triaining set and their labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjKqfy3_av3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qif0DtcMb5jE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "819e3c72-3019-4be3-bb41-3f5d4ef7d779"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(trainX[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD8CAYAAAAfZJO2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmGOveydcEmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX = trainX / 255.0\n",
        "\n",
        "testX = testX / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zzHBkLmcu4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4d7a04ba-338d-49e4-e6a5-ddc4586f2aa5"
      },
      "source": [
        "trainY\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYNR0aq6Pqka",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "b1deb4de-2ceb-4e6c-fa1f-d157f28c8f42"
      },
      "source": [
        "#Lets print the image as well\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(10):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(trainX[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[trainY[i]])\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAADuCAYAAADRE7iBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvDML2OoOIUx",
        "colab_type": "code",
        "outputId": "9dafc94e-61a8-4089-be03-d143163d68aa",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAABSCAYAAABwglFkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJztnXl8XFX5/z+ZmUwmyXRL6UqwKaVl\nL6UVLEsptGwqBVrAFlnlBS8papVNEHghqFihKpuILCqUCrzEsggUsGBRBKQgYqllh0ibUmi2Jk0y\nmUwmvz/m+3numXPvTCa5k5n0x/P+Z5KZO3fuuWe5z/M5z3lOSU9PDxRFURRFUZT+ESj2BSiKoiiK\nouzIqDGlKIqiKIriAzWmFEVRFEVRfKDGlKIoiqIoig/UmFIURVEURfGBGlOKoiiKoig+UGNKURRF\nURTFB2pMKYqiKIqi+ECNKUVRFEVRFB+oMaUoiqIoiuKDUCF/rKSkZIfeu6anp6ekt2NyKWNJSQmy\nbeOzxx57AAB+9atfAQAeeugh/Pvf/wYAxONxAEBXVxf22WcfAMD8+fMBAB988AEAYNmyZWhubu7t\nMjzprYx+6nD06NEAgLPPPhsAsHz5cgDAli1bsn5v2rRpAJz7snLlSnR1dfXrGvJVh17U1NTg8MMP\nBwCccMIJAICGhgYAwIoVK/D6668DcMpx0kknYe7cuQCA9vZ2OQ4A7rzzzv5cAoCBLaMfxo8fDwDY\nvHmz73P5LWNJSQnP4/k52+qcOXMAAOeeey4AoLm5GW+99RYApy8OHz4cBx98MADgn//8JwDgiiuu\nAAB0dHR4/nYu23gNZF8cDORzPDXOmfG42bNnA0iNk5s2bXJ9XlNTAwA44IADAKTGXb8M1r6YT7SM\nKUoKuTff5+KGepQx28BNQ2HRokU46aSTAADd3d0AgMrKSgBAeXk5Ro4cmfE33333XQBAMpkEAOy+\n++749NNPAQDPPPMMAODnP/851q9f39vlD9gAHo1GsWjRIgDAd7/7XQDOw6i+vl7+5uuQIUNQVlYG\nAKiurgYAPPbYYwCAl19+ud8DXT47/pe//GUAwIUXXggg9eAMh8MAgFgsBiBVDgDYZ599MGbMGABA\nbW0tACCRSOCTTz4BAGzbtg0ApMw777wznnvuOQDAkiVLcrkcYSAHt+eeew4jRowA4BiK5513HgCn\nXCbjx4/HmjVrAKTaMQD873//AwAce+yxaGtr689l5LUv7rTTTgCcdnnkkUdKPfD6+P8ee+whdUq6\nurrk4cz6ZFkbGxvx97//HQBw6623AgCamppyKKEaU0BuZQwEAjL2kerqapxzzjkAgIsvvhgAMHTo\n0Jyui+NvIpEAAFx22WW4+eabPX8XgOu3TdTQSPG5KKMaU7mTr0YzdOhQUWWmTp0KINUxW1tbATgP\nYqov3d3dKC0tBQAMGzYMQGqQZyf2qsNIJALAGdTD4TBeeOEFAMAZZ5yR8doGcgA/5ZRTADje+pVX\nXgkg9cClocGHVlNTE7Zv3w4AWL16NQDggQceAJAyzB599NF+XUO+6nDSpEm45pprAEAM14qKCtcA\nywF5l112ke/ys2QyKUYUj2OdNzY2YueddwYAURkvueSS3i4LwMAObs8//zwmTZoEwKkrtrHW1las\nXLkSAHD66acDAILBoLRnloP1v99++/XnEgDkz5iaNGkSHn/8cQBOPcZisbS+BwCdnZ0AUvUSjUZd\nn9GIHjVqFAAgFEqJ/uFwWD6j+vib3/wGjzzyiO8yft7HUy9jhurv5MmTZQzkfadhHIlExKBlmxw3\nbhwqKirSjme7jkajaGxsBAA8++yzAIDTTjst63Xkq4z9paSkxHVd5nPCVPPsz0youL700ksAUo46\nkHLg+Z1iGlO5liMT9913H2688UYATtvhuMY+/3/n7bWMGjOlKIqiKIrigx1emfKKPxgyZAgOPfRQ\nAMBTTz3lOj4YDAJw1IBM5yX5tsCfffZZTJgwAYAzVZJMJsWb5XWZ10Avg9NgLIP5WbZy9PT0YNy4\ncQCAY445BgDw9ttvu44fSG+Y3txnn30GwIlLWbJkiUwd0Stobm7Gv/71LwDA7373OwDAxIkTAQBb\nt27F008/3a9ryFcd/vrXvxbFhZ5fNBoVb5h1SC83kUiICsVjksmklJeYUww8P2Pjli9fjieffLK3\nSxtQT3HlypX44he/CMApW1VVFYCUKsO2yKmtqVOniuLD9s1pPsYj9Yd8lfGPf/yjTPNRfSgtLZU+\nT4WKddzZ2SkeK+unrKxMFGMqyF59lwpVaWkpTjzxRAAQ9bU/Zfy8KlNeU7Uvv/wyAEjb3LJli/Qt\nHscxs6enR1Qo1k17e7v0PdahGe/G99hWHnvsManDbNc1GJQplitXGPe57777YvLkyQCcGRSW8eij\nj5Z+MJBl9Hq+e93nbHFzrDszzpgK+pQpUyR8hPXJfspn7f+dU5UpRVEURVGUgaSgq/kGgkAgIJb3\nbrvtBiC18oZeBefJ6UWuXbvWpUiZVjwtXPMYUwXyw4wZMwAAEyZMQH19PQDHWw8Gg6JYMFbG9J7o\nIfP47u5uuVZa3rzm1tZWCYg1y8H7xJVJucbg5At64fTuqFBcdNFFEmTOmJOPPvpIVDsez7Lb8+TF\n4J577pHA861btwJIxdwwONlebRiPx6UcpKWlxXO1F4+n2rFx40YAyEmVGmg+/PBDzJw5E4DTtuih\nmvXCYPRZs2ahrq4OgBODwnZdTKjSjh07VhRDeqSJREKukYtAzPgT9iO+RiIROc4OXu7u7pZ2zzGo\nsrIS8+bNA+DEASq5YysP8+fPx5e+9CUAkHGvpKRExkU7Zqinp0fiU9lmA4GA/M06ZHtNJpNSnx9/\n/DGAlDLDBSic/SjkLA/JtLipp6fHU5E688wzATirTmfNmgUgNTvAVbZUod577z2JI/re974HAHjj\njTfyXYSs9PT0ZIyL8pqdCYVCMqbyPY7Fhx12GB5++OG0995++21861vfSjt/f1eKqzKlKIqiKIri\ngx1emQoGg2KBMwbjyCOPFA+F8+b0NI866ijcfffdAJzVO15WPFfsJJNJiQ3xyxFHHCHXxOui1xQM\nBsXDv+yyywA4+Xg2bdokOXq49DoQCMicLs/Fa54+fTq+853vAECaAsbfOvnkkwEUXpmyFUFTqeF1\nMudURUWFKHSsG9OzLDZr166VOI3jjz8eAPDKK6+Iesb2RnUtHo9LGalQVFRUyPEtLS0AHGXOPMfl\nl18+oGXpCxs2bHAptVR/4/G4eLWko6NDPEu7rMWEMXpjx46V9kVlqrKyUtqq3U9LSkpcnnIwGJT3\nzOOAVNtlnbL+w+EwjjrqKACqTPUFtjt7rH744Yfl3lIZbm5udqn5pqJB1cJrLOF75rhjzwJs27YN\nq1atAuConBy7QqFQ1njcQsO8dqFQSOKhGFvGfnDPPfdInCPVqBkzZkjOLT5rOPvz/vvvF+bikXm8\nN9sB/zZVJfZFrqR+8sknRSVmW7roootEOe8t91xv7PDGlBkkxoqvqamRm8VOw3xL+++/P2644QYA\nwGuvvQYAePPNNyUR34EHHph2rpdeekkemn6hEZNIJFwDQyQSkemGu+66C0BKSgZSxtHvf/97AMA3\nv/lNAMD69esl8JfnonF444034oILLgDgDCSRSESMQnauKVOmAHDyVA009gDGsgeDQQwfPjzj9+xG\nzjIVm1tuuQWAk5/o448/lik/Ghi855xWAJz6amtrk7JwkOZxw4YNk+mDwWB8kLq6OhmwWJ+89k8+\n+UQGYpajrq5Oyst6ZDsvJjT6gsEgxo4dC8ApTyAQEIOXDg0T4tbW1rpCB9ra2uSe0CDj+Y877jg5\njm08Go3KtKCSO7YRxcDh5uZmeUhyYU9zc7MrPQnJtmDHxHTezLEKSNU5p5NooDz44IOe1zmQZHrw\nV1RUSFoDGnktLS347W9/C8DJjcf2feONN8qCIJ7znXfekdAUGv9sy4U0prKlnmBKHRqFI0eOFEOR\nn3GMbWpqknvBEAoucsrLdebtTIqiKIqiKJ9DBoeL3w9MtYJWMy3S1tZW8fyovvD11VdfFaua02IH\nHXQQFixYAMCRCV999VUAqWBtM3mXH5ikcOPGjWJtm0vj7Qy9XP7f1taGvfbaC4AzNffII49IECst\nb1OepTdmBsbSsmcQ5UEHHQSgcMoU7zfLTC8nGAymTXcC3kvL+cpA/WJiSvlMw3HdddfJ52ZKBCAV\nzEpPlvUVCoWkbdneciAQkGSSg4nNmzdLH7GntmKxGDZs2ADAUasCgYAru/tgWEBAFeGFF16QlB1c\nNv3Tn/7UM20IkPL4GZjM18rKSmmTVK04ffeDH/xAxhJ6yu3t7dh1113zXqbPGxy/AEcRtIPIAe/w\ngFzaoPk9+7ylpaVS53zusE0VMgyB46UdZB+NRl2pVQ4//HCZ2Tj22GMBODM2gJOyhowePVrShTDk\nglnlX3zxxZx21MgHdhmZNPimm24StZdK+N577y3TdnvvvTeAVKJhIKWSs51w3O1tlqMvi89UmVIU\nRVEURfHBDqNMZfMkfvzjHwNwAgEBJ3iXygBjqw499FDxJGjpvv7666JW8Xgul9x1110l1qm/0DNg\nPI0ZM8VylZeXS7Cy/b3Ozk4pG9WPkpISl0JgemqcCzeDuFleKiRcFnvvvff6Kl+u2KkNvJYle73H\nOqF6k69UFX4w4zC4KOCDDz6QxKL0CukxJZNJeY/l2L59uwQn22Vk2ojBRn19vWwIS/WG5SopKXF5\nevF43OXV93fpcT5h3GQymZS9A7mZ+NChQ6VsvHbGrTU0NMgWJCyHqVwwFoNe8QcffCDKF+N6Ghoa\n8qZ295dsy81tlSNbQLXXvngmdtqWfKo2HMfC4bArTskcH82kjUCqPHbcZiAQyBjTaZ6D9RYOh0WF\nZP0WekEP4L1VDJC6NywPF2atWLEC559/fs7nHjlypMyWML6Y5S8rK8u6X2w+sccLxi+effbZrmem\nF3zuRiIRvPnmmwBSyXqB1HPSVr7MZ3NfFhLsMMZUtk7IfZZocHR0dMiUAgd3TjHFYrG0/CFAyqhg\nsB4bIIPx+ptp24Sr8/i727dvd+UyicViUnE09thYq6qqpDNzqqCrq0seYpQuKXkuXLhQAvI44Awb\nNixt8DF/p1CY2YYBpC0SyCbPk2I/gHojEAjIaiK2LbbDlpYW1ybI5uIJu9PakvtggQGcgDsA3Zyq\nZN2Vlpa6VlXlutHvQMLpjblz58oG41zwce+992Lx4sUAnD7FVUzRaNSV5yYcDktdst5XrFgBIGVM\ns//zmKamJgkr4LjD6ZRCkWk89co47fVA4f256qqrxGHzYiAMZ4ZLcDVwS0uLTLnxHkciEZfzYu6J\naRsh5ns2Zp4/jlMjRoyQ3yrmyr1M9dja2iqr8/gKpD9v7O/bC33GjRsn7ZJOIRfFjB8/XoL9i0VD\nQ4PLwfZqb3SWFixYIGPP7NmzAQDXX3+9yxA3/++LwajTfIqiKIqiKD7YYZSpbNj7LAUCAVE/GPxK\nObCmpkYsb3NKieegVWrnqPADd9zmEuzddttN5FMGiL/33nvy28xOa3pS9tLcUCjkUnNY/tbWVgkq\nZ7nM3CqcAnz00Ud9l60v2EHWprxqp7IwoaJBZYqqYbGxPd5NmzbJknh+ZuxfJQqOmQ6DaiE9RXrb\nDKIE4NqzsdjYCqG1FxkA5550d3dLee0ps2Lys5/9DEDKk2V/YHqUefPm4eqrr047nh5vZ2enK++Z\nOW3POqYS3tTUhLVr1wJwVL01a9bgvffeA1B4RcrGViO82tipp56K/fffHwBwyimnAHAU7/r6egm2\nP/XUU13fpRr7/e9/HwDwk5/8xPc1m7tG8NrtDPRmBnRznOf/dt/NpI7zM94Xc19XHsfdGwYb9vSV\nObbmsm/fqFGjZGqa94bnjEajRR+PTBXVVKTs8XL58uUAUm2X5abSbC4MIlzsddttt0m+ylxQZUpR\nFEVRFMUHO4wyZXsXtKij0ahkB6fH3NnZKbEqnNemUjV8+HBRqajahMPhtGSJALBu3To5v9/Yottv\nvz3tdcSIEbIbN2MPZs+eLV4ql5wy0LW0tDRr0LV9b2KxmKscDJIsFiNGjHAF3dOryJREjx4VPQ1z\nbzPGSPC9wUBtba2UhR45Y9dqa2vFU+I8fFNTk2t/O36/2F5fNjLFlpiB2GaAs13fDNwtJtyja+7c\nudK/GQ/y5z//WdRPphExlSe2PTPYnvXFcYbjztChQyW2hPubTZgwQRI9Mui9kHuemR69HXOz2267\nifrEeK6jjz5agn7pqVNdrKmpwVe+8pWMv7Vo0SIAkL3z8sH06dMBOCpgT0+P9Bve946ODlEHzdhE\nHm+3YVMdJ/zfaw+48vJyeWZQvWEZX3nlFT/FyxtesUBUYeyyesXKVVZW4qyzzgIAPPHEEwCA+++/\nH0CqzPnaGaS/ZIoXs+uW197Y2CjPRc5YzZkzR9o0xwQyYsQIfP3rXwcAnH766b1ejypTiqIoiqIo\nPthhlCl7BQ2t7oULF0osEpdAlpeXi3XKuXTGPsXjcVGtzFVGXOVA1eC2224DAEybNi3v25eYcRRU\nJObMmSNlNPcIY5lta9vcI8xeORaPx8V7ZrxWsens7EyLH7Kx3zPjGgjrftu2bYNKkSIdHR2eHi+Q\nunbWCd9ramqSGCmuAiT0ugcjmZTEkpISl8cbCARcS80HQ8wb4yI6OjoklomxiocccoikJfHaod5e\nCWb2RTtOZcuWLeLNU3368MMPsXHjRgD5T5hrxwKZKw2J2de4WpEpVxYuXCiKA1N+rF27Vtojx0mm\njqiurpbUNGT06NFYuHAhAOCXv/wlAGcLqxkzZvjewsNW4pPJpOcqLju1CsfH7u5uGdO94okI71NZ\nWZkoGeaYbJ+XyqNX7Fg+8buHHABXDK75HqmvrxfllOrtHXfcASCVOLNYzxav8puKeKb7smnTJhln\nuRXbE088IcdzBTXb0vPPPy99IBd2GGOKjd8eGNavXy8PaXZ4c/NjDtx8+DY0NMhxfLhVVlbKkklK\nfpT3li1bJoOsX8zNMlkOVmRLS4vLUMy2bDUbZgfhVKH5fqbcJANJT09Pv/NDmYPaYMI2nBKJhBj0\n5jJ4wr/5WXl5uXRg5pvilMFgxs5RZA5k9jSlmXuK7zFPVTFhBvJQKCQBxDSq2tvb5Vo5lWOWK9OG\nu4DzsOWAPGrUKDFOOJBXV1eLEUNH8MMPP/RVHq/pVcA9XgLp6SA4zjH0YcOGDVJ2LpIZOXKkTA+x\nLHy4btmyRc5x6aWXAkgZqMznwz7Lsdbco7K/2OcwN303UxjYBpJthPWGV14qlmfbtm2uRSaF2pkh\nn+O2VxueNm0aAOA///mPZHU/7rjjAADHHHMMgJSRToeg0GQrf7acZ/vtt5+EvTA0aNGiRdLOr732\nWgBOH169enWfrkun+RRFURRFUXxQNGXKlsXNZav0CEwrM1NA7qpVqySg1UxKSeuVSgF/JxKJuCTh\nrq4uV/ZTLnHP5w73Xss4GdjZ0tKSUX0zA3uz7S/F75lTROYy9FyWww4UXtMkXh5its/M68+2k3ih\nsK9hyJAhEnBOD55yMpCSzQFn4cOwYcNcdc06NRPiDbZgdLvdmX3X6xhbyRkMypS5WIPXRcWjoqLC\nNR6YiyfsvSJLSkpc7ZZT9cFgUOqdVFVVSV+nh+xXmfLK2k2WLFkCAJL9esyYMaLAU0Hi95gUGEhX\nsO22znHV3E+U0z7z58+X96666ioAwAUXXAAgFdCfSzBvNq644goAzjiaSCREMWJ/q6+v7/cekKxr\nMxErz8+xtbW1VaY8+dw58cQTAWSfahoseKmrTC7Le3j77bfjjDPOAOAol6tWrQKQGp+8VM9CYz8X\nQ6GQa2aHx3R2dsrz0KttXHnllQCce/PQQw/16VpUmVIURVEURfFBUZQpM6YpV6/7sMMOAwCZ6z/k\nkEMApBQAWs30Bk3r1N66pKysTOa2abmaSzx5DsauLFiwAI8//nify5iNQCAg10evxgyM5z0x97Kz\nrWzTQ+ZnnLuvqKhwBV8Wm0gk4lqObSbJy7bvnu199PT0uLZmKQa2KrZ161ZJa8F4AqpQsVhMvH56\ndLW1tXL9XLLLgEcqFoONKVOmyL23U1cAbpXKDM5mW2TQfTHxUpWYmsRcwGL3MfNvsx1TJbG3sQoE\nAhKLxbru7u6Wdm4vPOgP06dPx1FHHQUA2H333QE48Tvjx4+XFAGMn6yrq5P2xuPMMZHjoZn0kuOV\nHbjd0dEh5TrwwAMBpJIC8zepgDFJaUVFBc477zxf5WW8m7lPHO8797QsLy/3HajN78fjcSkPy2/G\ngPK92tpaX79XSGyV+JprrpHyUHU8+eSTpd5sJXUgtgkyn2mmcmQmr+6NZDLpuv+vvvoqgFSyXMZ8\nmZgqMuC0IVtR7o2iGFNeUjSlxfHjx0sOJlbcggULMGXKFADufDzt7e2yAo+ZjGOxmNwgBqDzAVZR\nUSFyNDvIYYcdJhXFaT02lpkzZ+ahxOmYlW1mirYHaXOqy552ANwBlWb26WwPgWJgPlRzmbLMdA6S\naxBpIZk1a5ZM17BD8kHT0tIiUyJ8kHV0dEi7NDfpBlKByWy7DFLvbVPZQrDnnnvKA9LeSBZInw4j\ndqAujcqDDz646KtNzZWyn376KQBnxZqJuXLWNJT4amfPNvupPR1iOlN+Nu3+9re/DSA1PvKaTQMA\nSNUNjSN+Fo1GpcwMkaChFQqF5DMaWCUlJWKs8Hr5e5FIROqfUyiJREIWW9CA5vF+jEfuAUgHxZw2\nt/dGNOvVa28+uw4Bp+7sHSU6Ozulz7LNx2Ix6c8sYz52y7DJttgh1++y3sPhsLQFrq5ctmwZgJSx\ny+u/+OKLAaSPzwxKpyH78ssv9/l6eC22M20+9/yGoJjj48qVKwE4U9nf+MY35DOzTbAtsF1xBWNf\nGXxPJEVRFEVRlB2IoihTM2fOlNwkXBLOpcKmBE5vKZFISHAoPRBatR0dHeLdfu1rXwMAvPbaa+IB\n0Rs2g1733XdfAI6XtHHjRrHY6UFRtSrUztg777yzeHPmnlNAuuebDVrbXV1drgD/YtPbddjeivm3\nnesnGAzmPfdXXzFVInp0e+21lyhTbM+c0nr//fdlye3EiRMBpNq3GcBrsn37dllyftNNNwEobrA9\nmTt3rks59VIazb/t9sxFF4sXLy6aMuWlirL/lZaWuvYYNKcqbdXXPBdVCvPecEzheGYuofeznP6+\n++4DkJrGYLZy5sfiuGUuimCfMafVOf7y1cwEboZN2EowwyDa2tpkTGbZw+GwKLI8BxWwzs5OPPnk\nkwCc/fpyZdasWWn/U8Uwc2nxd6uqqkRFsuuyr2p9PB6X54O52MTemWEgxlpTqbGfAb1du61+tre3\ni7pH9emvf/0rgNQzmZnvvbDH4P5mP8+0mMqGytk555wj6hmnH4k5Bps7YtC2oLLP0CATcyy1Z304\nPgG5zZjI9eR8pKIoiqIoiuKioO49Lb9bbrlFYkTseWqvYHBzTyHCOewJEybIDvA8ZvHixWnxUwDw\n3HPPAUgtQWZMFmOt4vG4zPub6g7gtobzgZdFbgaKm+UGMscb2RnQWYbOzk75DTOepdgxU5mWrJpe\nr5fX6JV8j/Vvpn4oJKZnw6DGDRs2iIdk7l0GpIJ+6W3xu5s2bZIUHIzXMfftoxfJHc7ff//9AStP\nrsycOVP6htdei16KIevP3k/xoIMOGvDr7Q+RSMSlSHkFxmYLSqdSEggERJli/U2bNs2lsPcHfnf9\n+vWu/eAY4zRx4kRpP2yL48ePT4uHMsuXTCYlFonqU0NDg6hq9mtHR4dLpQiHw65y8ZxtbW39Hofs\noGczfpa/R0U4EAjI8XbMVCAQcO3lZ44xtsIUj8elzfL4qqoqOa5Qi3z6ct/M2CRT3brmmmsAOPHF\n++23HwBIxvpM8BxU2vuaFsFczMB64H2jknTeeefJYg0yceJEnHDCCQCcxRUkmUxKvbN+dtllF5mh\nsveMLC8vFxvBbBNUbnld//jHP+Q7qkwpiqIoiqIUiIIqU2eeeSaAlJrEeUnGJvHVTHJIa3bYsGGy\n1JwWNSPvP/30U9x7770AnKRpjz/+uHhhPO+MGTMAAEcccYTLKykrKxM1iNASLy0tHZBVGjadnZ0u\nT8fc/sWes47H42mJygDvVA/01IpNaWmpp3fP/3PxukxlazBtLUN1ad26da54E/M6bY83mUyKN2R6\nVkBK2bLVrcGgTNXU1EhskdeKUTs+yoSfse+OHTtW7g9VhkLBGMzKykqX8lleXu7a7slUIr3SlNjl\n9trW5OOPPwaQ2oqF5fUTZ0N1qLKyUpR+u281Njbi+eefB+Aog6bC4xWfyePMtswxhp9xXB01apTE\n/XG87urqcq2Q4v3u6uqSla595W9/+1va/2bd2CvwEomE6x6b46W9Ss5Uzu1EreZ5Wa5QKCTj9EAq\n/qbqy7Gcq2HHjRsndWvjdU3XXnutXDPHLDPBKjHVZTtNT3/TmmRLpTB9+nQAqXLZsxGfffaZxPPN\nmzcPANJSFdnlvP/++/H0008DSI99AuCa3SK8n4zr628cZ0GNKS7x3rhxoytAnMZSNBqVBxE7aWNj\no3RAdmLemFgsJhX+yCOPAEgtheQDiMYZB8fm5ua0zLlAqjNyILDl/XA4LGkZBhKv4GKvQL1s0w3m\n8faSZPs8hSYUCrmC4nO9HltG7+rqGhSpEdjGmBsqEonI1Ii9H51ZD2a7s41CGsJjxoxBXV0dACc4\nuJhQCt9pp51kStLO1+Y1tWBOwbBf/+UvfwEAnHLKKeLkFCoQnddgDtr2VHFpaalr8Dc3ITcfwMQM\n7gbSg53tPESlpaVpzppf2tra5EFgU15eLr/B34xGo66M3iQYDLr2V+T7JjSONm/eLPeB5SwtLXU9\nhPl/e3u7OMR95atf/Wra/xzT4/G49BG2zXg87jKAzOklr7AJO12CGSphB5mbxtRA7ihhjpHcnNt0\nuGisZgsIZ7jAwQcfLH3WDub3+k0vB+ILX/hCn8sAOHkiv/CFL+BPf/oTAMeBNHPqMTURc751dHRI\n2+ZCHK+8j4899hiA1AIMiioBRjaLAAAKLklEQVS5QiPVy9jSaT5FURRFUZQCUVBlip52T0+PJP7j\ncnHKh83NzRKsyODvUCjk8qRoYQ8ZMkQ8CX5vzz33FGuWihenJsrKyuQ4U6Hi31QQuJv7tm3bJGHZ\nQOKltHgpN9mUKdOjotdEz6XYmNOotueTq8pkTqEMhnLRSzMzgbOcbJ925mjAUXkSiUTatAEAfPTR\nRwCAyZMni5fNYPuqqirx2AoN+4A5HWIrp+YUkZklnZ+zTTKQNBQKYc899wRQOGXKDhQPhUIyLpFg\nMOjpnQPei0HMaSZbde3u7hYV/t1335XftBXwgaKjo8PlcXMs3NE49thj0/7nmN3Z2Sn3ePHixQCA\nFStWSBukisZ7Ho/HPevLrnM+cyKRiPRBTjVOmDBBplltxowZI303F7KlCjA/628fufPOOwGkdi+w\n1T0vvJRXvsdFNH2FyT7vuOMOCTinik9lavv27VKnVN+qq6tddXXDDTcAAO6++25cf/31AFLhOwCw\nevVq2RElVzhF7rWYqS+zOapMKYqiKIqi+KCgytQbb7wBAHj44YdxzjnnAHACypnsMBaLSVwUVajy\n8nLX/jmMtTK3YeG88SeffOKK3TATrPH8ZhwVvQw7nmrixIl98jJyIZO1mykY1UyD4HWsfb58bVeR\nT8LhsEuhyNUrp3LFMnV1dclyb7apYsB7a25tRMWMbdfc5oLlZ/szg2QZ1/Daa68BSMUYMBaLbXfE\niBFFU6YY/FlfXy99xN4zKxqNSp2aCjI9Pn6Pqm8ikZAEuoXGVNNsZSoQCLhSi5h7R3qpVfZ4Y7Zt\nqhr//e9/5VyZFmMombGVJs5qmPXBuNlbb71Vkt5StTK3HbNjFc3+yT7L2ZLu7m5JPXHzzTcDAGbP\nnp1xz7jjjz8ed911V87lyqZ+eCWXXbVqFYDUmLF06VIAwAMPPOD67tVXXw3AUfRuvvlm2Tu0r5hj\nUH+45557AKTSH+y9995p52Kf2bJli9Qp45jq6+tdiW0vvfRSeeXsFdXXH/7wh3KcnRIjE/wtL6Wx\nL4mSi5JGeunSpfIQvOSSSwA4wbz19fVSKE7VBYPBtGy8fA9IH8g48JWWlsrxZn4Lwr9pJEWjUQlU\n583jgL9u3TqsWLECgJNx2C9eq9fi8XjGqSszK7FpiGTrhF7GVDED0M0gQ6+9BL2C0u3OYGah7usm\nlAMBB1u2ta1bt0oGajvfVDgclrrj4G5miubqGmaHbm5ulvPaGayLwaRJkwCkrp19g/VDA2/s2LFi\ndD3xxBMAUoOcvaKLVFZWysBaaExjiqvsSGdnpwzSvGYzGNs2mMwge76aU0R8QNBoM3PtFDuT/44E\n64z9J9M0GwBcfvnluPzyyz0/i0Qicg5zGs02pnrLYWcH3vOBPm/evD4ZU4cffrj8Ln+TU7Fm5niO\nFXydNGmSZDJnHkUu8jr66KOxZMkSAM7UZKb7kQmvsdjvxvK1tbWy3y1DcPiMHjNmjNxTlrusrMy1\nwIrjjbkCmM9y01jM9rxj/+zo6BBnxxZNIpFIn8qr03yKoiiKoig+KKhbZCoNTz31FADIKwPIli5d\nKvtK0WIMBAJpS1KB9OWotMZpidbV1YnVyiA3L4WG0w7t7e1ybatXrwYAvPXWWwAKFxgLuKezTM/X\n3KEeSM/+Srwyhg+Wab5YLCYeiJ0zyyvHCwBXpm1zOqm/uWryCZUp3u+GhgZps2ynnKoLh8Mub9Mr\n8J7ttampScrL48eNG4d33nlnQMrSG1Sa6EUDTn2YaR94/SSRSLiyJbOuY7GY7OheKGwFCXArEGVl\nZeK5sg1Sue7u7vacprYzifOclZWVosqa+9Wxfdj57ZTMnHvuuQCcvdaoeJphDbkQi8V8KywfffSR\npGOw91x88cUX+3QuzsrU1NTIOZkWiO2vsbFR+hsVnT/84Q9Yt24dgNSemQBkj8apU6fKdVC9isfj\n/c7rxhAapjXpL0uXLpXp1+rqagBO39m+fbtrD14zbZHXlDtDJk477TT5jVym98y+y3qjHWGfJ1dU\nmVIURVEURfFBQZWpbJbimjVrAEDmUwFnGeZOO+0k1j+tWSbA6+rqcmU6Hex4zeVu3rxZkoOaSR35\naicVNQMmvZbf2+pPpt8tFGvXrpXyeSVJM+OhAO9rNfdz5DLzYkKviF6bGZxJb4ceVigUEq+T8TiV\nlZXyHlUuxiYlk0mXh8U4j2LAGJA777xT6opxa147sJP6+npR6+hlsxxDhw6VgN5CYe4gAKTam+2B\nrly5UpQBeqt28knzPTNdgr3v2LZt22RRAUkkEvL5YEg+u6PAZwBnLqi8DBs2zDMA28ZU972y99tj\njjnW2ukLnnnmGVHK2J4Z78jl+rnC4GwvGDRfXV0t6qip6PBeUJHitaxatQr3338/AEfJAvq/0wCV\nvAsvvBCAs59eX1m/fr3cSwbG/+hHPwIAHHDAAdLvcuWFF14A4NgPuWKOU7x3djLZvj4vtScriqIo\niqL4YFAvJXn77bdd7/V3aedgZ/jw4bLqx94HyfSkvLafsOONNm7cKPEEVDp4HqBvyz3zRXt7O5Yv\nXw7AiY9j+SorKz13YLdjyJjQcs2aNVm3TygUkydPBuBcl7mEl9fOeojFYhJ/x5iBUCgkq3DsmLjh\nw4dLrJRZ7mKz7777uuKcTG939OjRaZ+NGTNGYqrYruk9H3PMMQWPfeO1mDFO9v6VXG4+UPT09KTV\ns9I3uPqS8T9DhgwRtYZUVla6ttjJlMogF+zx6Y033hCllQr1bbfd1ufz9gYTUPY1EWW+4UxQPsvI\nPfT4CkBmL7jN1NSpUyVtjJ2Woa6uDueff37ae+ZK2WyYYxaTgNrxqHasZ2+UFHLqp6SkpHjzTHmg\np6en16QwuZTRK63BsmXLZHCgnG0aThx8GeBr5p6ypwXj8bg0vLVr1wJwAoh7o7cy9rcOs6VyqKqq\nkuX2psy7ZcuWtFczaDRb1uBs5KsOAffUTyAQkDqgEUtjobq6WgakgSafZczGoYceCsDZM2zOnDky\nDcDA+2XLlomB9eCDDwJwFp34wW8Zf/GLXwBIGbucnmEf8dpdIJ9cd911khGaDobXPRmovjhY6G8d\nsn7OPPNMAKngbLY3Tqmae+flA3tj5Pnz5+Puu+8G4Dx0zzrrLADpQdqF6ovFRMuYQqf5FEVRFEVR\nfFBQZUpRFEVRFOX/N1SZUhRFURRF8YEaU4qiKIqiKD5QY0pRFEVRFMUHakwpiqIoiqL4QI0pRVEU\nRVEUH6gxpSiKoiiK4gM1phRFURRFUXygxpSiKIqiKIoP1JhSFEVRFEXxgRpTiqIoiqIoPlBjSlEU\nRVEUxQdqTCmKoiiKovhAjSlFURRFURQfqDGlKIqiKIriAzWmFEVRFEVRfKDGlKIoiqIoig/UmFIU\nRVEURfGBGlOKoiiKoig+UGNKURRFURTFB2pMKYqiKIqi+ECNKUVRFEVRFB+oMaUoiqIoiuIDNaYU\nRVEURVF88P8A0wyYl+ZpGWEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f60784a5950>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "label for each of the above image:\n",
            "9 0 0 3 0 2 7 2 5 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4TbJGeSOIU4",
        "colab_type": "text"
      },
      "source": [
        "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9JTwixKoYF0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2a428f78-3ca4-400b-8abd-574eabddc465"
      },
      "source": [
        "trainX.dtype"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac06XZZTOIU6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "cd4ae4a7-db38-4cb1-b425-ade8c0f69f5b"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8YB_J67q107",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "715Cy7UVq5v-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "35a2cb8a-e652-4077-aefd-5a5f00e4255f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape (Reshape)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hQpLv3aOIU_",
        "colab_type": "text"
      },
      "source": [
        "### Execute the model using model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O59C_-IgOIVB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1053ae50-a075-423d-ff99-6fbeb66ef7df"
      },
      "source": [
        "model.fit(trainX,trainY,          \n",
        "          validation_data=(testX,testY),\n",
        "          epochs=100,\n",
        "          batch_size=32)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 2002.1134 - acc: 0.7413 - val_loss: 1293.4275 - val_acc: 0.7940\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1587.5383 - acc: 0.7795 - val_loss: 1189.6921 - val_acc: 0.8015\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 1528.2648 - acc: 0.7882 - val_loss: 2199.4974 - val_acc: 0.7608\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1562.3051 - acc: 0.7875 - val_loss: 1125.1433 - val_acc: 0.8141\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1484.9815 - acc: 0.7937 - val_loss: 1546.7480 - val_acc: 0.8032\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1450.9423 - acc: 0.7955 - val_loss: 2090.5576 - val_acc: 0.7750\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1465.6047 - acc: 0.7952 - val_loss: 1129.0810 - val_acc: 0.8187\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 1434.8753 - acc: 0.7998 - val_loss: 1149.6554 - val_acc: 0.7988\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 1466.0043 - acc: 0.7990 - val_loss: 1792.0480 - val_acc: 0.7341\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1446.3212 - acc: 0.8015 - val_loss: 1284.8577 - val_acc: 0.8045\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 1421.7714 - acc: 0.8022 - val_loss: 2280.8838 - val_acc: 0.6961\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 6s 96us/sample - loss: 1414.0170 - acc: 0.8003 - val_loss: 1772.2140 - val_acc: 0.7874\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 1421.4987 - acc: 0.8015 - val_loss: 1616.6376 - val_acc: 0.7862\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1419.2475 - acc: 0.8014 - val_loss: 1014.6524 - val_acc: 0.8262\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1378.6900 - acc: 0.8031 - val_loss: 974.2749 - val_acc: 0.8208\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 1385.9151 - acc: 0.8030 - val_loss: 2623.8826 - val_acc: 0.6980\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1391.8673 - acc: 0.8030 - val_loss: 1673.9327 - val_acc: 0.7830\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1401.9556 - acc: 0.8050 - val_loss: 1047.9948 - val_acc: 0.8219\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1435.2707 - acc: 0.8023 - val_loss: 1106.6810 - val_acc: 0.8291\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 1422.6592 - acc: 0.8062 - val_loss: 3397.7175 - val_acc: 0.7228\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 1393.2382 - acc: 0.8053 - val_loss: 1989.4073 - val_acc: 0.7453\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 1394.6396 - acc: 0.8063 - val_loss: 1316.7667 - val_acc: 0.8018\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1395.0292 - acc: 0.8048 - val_loss: 1306.8000 - val_acc: 0.7941\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 1396.3325 - acc: 0.8080 - val_loss: 1479.1724 - val_acc: 0.7431\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 1393.8568 - acc: 0.8066 - val_loss: 1561.6274 - val_acc: 0.8025\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1381.5508 - acc: 0.8071 - val_loss: 1057.7699 - val_acc: 0.8257\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1351.7798 - acc: 0.8095 - val_loss: 2462.5325 - val_acc: 0.7483\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1379.3257 - acc: 0.8079 - val_loss: 1106.2985 - val_acc: 0.8220\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 1379.1258 - acc: 0.8064 - val_loss: 1805.5672 - val_acc: 0.7884\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 1360.6021 - acc: 0.8093 - val_loss: 1041.3905 - val_acc: 0.8166\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1399.3224 - acc: 0.8077 - val_loss: 1341.9878 - val_acc: 0.8094\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1368.6903 - acc: 0.8091 - val_loss: 1201.1092 - val_acc: 0.8111\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 1348.1315 - acc: 0.8098 - val_loss: 1167.2742 - val_acc: 0.7984\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1372.7085 - acc: 0.8094 - val_loss: 1446.1625 - val_acc: 0.7691\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1382.4988 - acc: 0.8089 - val_loss: 1998.6228 - val_acc: 0.7737\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1348.9039 - acc: 0.8081 - val_loss: 1257.3230 - val_acc: 0.7988\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1367.4340 - acc: 0.8101 - val_loss: 1141.9585 - val_acc: 0.8027\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1418.5364 - acc: 0.8063 - val_loss: 1545.8440 - val_acc: 0.8081\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1377.1576 - acc: 0.8109 - val_loss: 1282.7967 - val_acc: 0.7947\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1355.6390 - acc: 0.8087 - val_loss: 2739.6869 - val_acc: 0.7013\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 1361.3507 - acc: 0.8107 - val_loss: 1223.5652 - val_acc: 0.7789\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1355.6920 - acc: 0.8094 - val_loss: 1019.3190 - val_acc: 0.8236\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1341.9823 - acc: 0.8101 - val_loss: 1476.2968 - val_acc: 0.7779\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1347.4998 - acc: 0.8102 - val_loss: 1382.8321 - val_acc: 0.7858\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1362.3886 - acc: 0.8113 - val_loss: 1035.5092 - val_acc: 0.8237\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1357.2397 - acc: 0.8106 - val_loss: 1257.8252 - val_acc: 0.8012\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 1314.4080 - acc: 0.8124 - val_loss: 1259.2543 - val_acc: 0.8195\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 1334.3473 - acc: 0.8117 - val_loss: 1138.6834 - val_acc: 0.8229\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1348.3991 - acc: 0.8113 - val_loss: 1449.2113 - val_acc: 0.8082\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1377.3558 - acc: 0.8090 - val_loss: 1433.8080 - val_acc: 0.7725\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1349.2820 - acc: 0.8117 - val_loss: 7435.9995 - val_acc: 0.6645\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1353.4445 - acc: 0.8113 - val_loss: 1190.8843 - val_acc: 0.8063\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1347.4789 - acc: 0.8118 - val_loss: 2183.0229 - val_acc: 0.7556\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1348.0312 - acc: 0.8113 - val_loss: 1488.5884 - val_acc: 0.7722\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 1342.9634 - acc: 0.8110 - val_loss: 1778.2561 - val_acc: 0.7693\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1362.5614 - acc: 0.8108 - val_loss: 1082.3760 - val_acc: 0.8158\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 1370.8538 - acc: 0.8108 - val_loss: 1044.7001 - val_acc: 0.8309\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1337.2678 - acc: 0.8119 - val_loss: 1159.3687 - val_acc: 0.8211\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 1310.2715 - acc: 0.8116 - val_loss: 1233.7804 - val_acc: 0.8016\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 1351.6736 - acc: 0.8134 - val_loss: 3061.7440 - val_acc: 0.6707\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 1334.8373 - acc: 0.8122 - val_loss: 1097.3188 - val_acc: 0.8185\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1323.1423 - acc: 0.8110 - val_loss: 1041.5407 - val_acc: 0.8202\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1332.6569 - acc: 0.8130 - val_loss: 1352.4265 - val_acc: 0.8054\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1394.9622 - acc: 0.8112 - val_loss: 1111.0480 - val_acc: 0.8206\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 1292.3797 - acc: 0.8148 - val_loss: 1174.8456 - val_acc: 0.8098\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1346.0006 - acc: 0.8120 - val_loss: 1430.3992 - val_acc: 0.7816\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1366.1668 - acc: 0.8128 - val_loss: 1114.8613 - val_acc: 0.8058\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 1321.3345 - acc: 0.8142 - val_loss: 1487.0026 - val_acc: 0.8052\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1338.3764 - acc: 0.8117 - val_loss: 1242.6728 - val_acc: 0.8141\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1288.9948 - acc: 0.8128 - val_loss: 2498.7556 - val_acc: 0.7187\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1326.0176 - acc: 0.8139 - val_loss: 1933.4671 - val_acc: 0.7358\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1315.5244 - acc: 0.8134 - val_loss: 1637.1219 - val_acc: 0.7819\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1325.4911 - acc: 0.8137 - val_loss: 1712.7286 - val_acc: 0.7844\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 1359.6031 - acc: 0.8131 - val_loss: 1338.2413 - val_acc: 0.8019\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 1308.7641 - acc: 0.8145 - val_loss: 1634.4648 - val_acc: 0.7729\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 1319.9610 - acc: 0.8120 - val_loss: 1082.1197 - val_acc: 0.8152\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1336.0402 - acc: 0.8106 - val_loss: 1352.7589 - val_acc: 0.7888\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1333.4432 - acc: 0.8144 - val_loss: 1230.6427 - val_acc: 0.8051\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1328.4841 - acc: 0.8139 - val_loss: 1722.3316 - val_acc: 0.7697\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 1289.6023 - acc: 0.8146 - val_loss: 2030.8849 - val_acc: 0.7962\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1314.3300 - acc: 0.8132 - val_loss: 1754.9368 - val_acc: 0.7955\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1353.7936 - acc: 0.8124 - val_loss: 1391.4525 - val_acc: 0.7952\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1342.7777 - acc: 0.8128 - val_loss: 2458.0852 - val_acc: 0.7522\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1338.4429 - acc: 0.8115 - val_loss: 2285.4950 - val_acc: 0.7670\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 1363.8159 - acc: 0.8119 - val_loss: 1320.6180 - val_acc: 0.8093\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 1324.9164 - acc: 0.8139 - val_loss: 1249.8300 - val_acc: 0.8091\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1319.8508 - acc: 0.8133 - val_loss: 1701.9026 - val_acc: 0.7697\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 1294.3681 - acc: 0.8148 - val_loss: 1604.3575 - val_acc: 0.7632\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 1379.5498 - acc: 0.8116 - val_loss: 1151.9631 - val_acc: 0.8188\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 1350.7162 - acc: 0.8129 - val_loss: 1552.3593 - val_acc: 0.7721\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1331.3211 - acc: 0.8140 - val_loss: 1291.5954 - val_acc: 0.7918\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1326.5002 - acc: 0.8152 - val_loss: 1453.4928 - val_acc: 0.7999\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1323.2612 - acc: 0.8156 - val_loss: 2835.9087 - val_acc: 0.7899\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 1305.4552 - acc: 0.8136 - val_loss: 2856.7428 - val_acc: 0.7562\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 1277.4396 - acc: 0.8150 - val_loss: 2305.7670 - val_acc: 0.7276\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 6s 94us/sample - loss: 1350.3305 - acc: 0.8122 - val_loss: 1144.9698 - val_acc: 0.8043\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 1353.8242 - acc: 0.8114 - val_loss: 1189.2751 - val_acc: 0.8120\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 6s 96us/sample - loss: 1333.5639 - acc: 0.8147 - val_loss: 1165.8251 - val_acc: 0.8162\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 1345.2513 - acc: 0.8133 - val_loss: 1528.2026 - val_acc: 0.7744\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 1284.7313 - acc: 0.8132 - val_loss: 1176.0950 - val_acc: 0.8057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff2c59038d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdzDtGwDOIVF",
        "colab_type": "text"
      },
      "source": [
        "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kndfpdidOIVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ltVjA-SxaKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x59esAYOxe-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "c91c78e1-1380-4682-f603-a0883510572f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_1 (Reshape)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 10,986\n",
            "Trainable params: 9,418\n",
            "Non-trainable params: 1,568\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXpCvmFuxiyl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1254679c-a930-49b2-e71b-a268d07b2b09"
      },
      "source": [
        "model.fit(trainX,trainY,          \n",
        "          validation_data=(testX,testY),\n",
        "          epochs=100,\n",
        "          batch_size=32)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.6014 - acc: 0.7923 - val_loss: 0.5113 - val_acc: 0.8233\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4898 - acc: 0.8312 - val_loss: 0.4879 - val_acc: 0.8334\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.4699 - acc: 0.8370 - val_loss: 0.4797 - val_acc: 0.8371\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4584 - acc: 0.8409 - val_loss: 0.4862 - val_acc: 0.8368\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4500 - acc: 0.8440 - val_loss: 0.4699 - val_acc: 0.8381\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.4412 - acc: 0.8475 - val_loss: 0.4688 - val_acc: 0.8382\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4390 - acc: 0.8474 - val_loss: 0.4716 - val_acc: 0.8396\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4376 - acc: 0.8477 - val_loss: 0.4688 - val_acc: 0.8382\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4335 - acc: 0.8487 - val_loss: 0.4773 - val_acc: 0.8393\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4293 - acc: 0.8499 - val_loss: 0.4628 - val_acc: 0.8392\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.4297 - acc: 0.8501 - val_loss: 0.4621 - val_acc: 0.8395\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4251 - acc: 0.8515 - val_loss: 0.4661 - val_acc: 0.8422\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.4255 - acc: 0.8512 - val_loss: 0.4707 - val_acc: 0.8423\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4243 - acc: 0.8526 - val_loss: 0.4680 - val_acc: 0.8386\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.4199 - acc: 0.8533 - val_loss: 0.4628 - val_acc: 0.8433\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4216 - acc: 0.8518 - val_loss: 0.4620 - val_acc: 0.8415\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.4182 - acc: 0.8532 - val_loss: 0.4795 - val_acc: 0.8410\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.4178 - acc: 0.8521 - val_loss: 0.4803 - val_acc: 0.8354\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4171 - acc: 0.8547 - val_loss: 0.4659 - val_acc: 0.8398\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.4156 - acc: 0.8543 - val_loss: 0.4618 - val_acc: 0.8446\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4168 - acc: 0.8548 - val_loss: 0.4707 - val_acc: 0.8379\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4199 - acc: 0.8535 - val_loss: 0.4664 - val_acc: 0.8429\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4163 - acc: 0.8551 - val_loss: 0.4673 - val_acc: 0.8403\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4126 - acc: 0.8557 - val_loss: 0.4647 - val_acc: 0.8415\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.4131 - acc: 0.8553 - val_loss: 0.4833 - val_acc: 0.8372\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.4130 - acc: 0.8548 - val_loss: 0.4701 - val_acc: 0.8430\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.4137 - acc: 0.8552 - val_loss: 0.4723 - val_acc: 0.8385\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4119 - acc: 0.8557 - val_loss: 0.4792 - val_acc: 0.8402\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.4134 - acc: 0.8547 - val_loss: 0.4760 - val_acc: 0.8402\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4097 - acc: 0.8559 - val_loss: 0.4663 - val_acc: 0.8396\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.4109 - acc: 0.8560 - val_loss: 0.4779 - val_acc: 0.8397\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.4103 - acc: 0.8542 - val_loss: 0.4849 - val_acc: 0.8385\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4103 - acc: 0.8552 - val_loss: 0.4728 - val_acc: 0.8426\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.4101 - acc: 0.8565 - val_loss: 0.4717 - val_acc: 0.8441\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.4111 - acc: 0.8543 - val_loss: 0.4746 - val_acc: 0.8421\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4101 - acc: 0.8557 - val_loss: 0.4796 - val_acc: 0.8404\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4060 - acc: 0.8570 - val_loss: 0.4665 - val_acc: 0.8428\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.4083 - acc: 0.8566 - val_loss: 0.4896 - val_acc: 0.8425\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4094 - acc: 0.8563 - val_loss: 0.4655 - val_acc: 0.8416\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.4046 - acc: 0.8566 - val_loss: 0.4701 - val_acc: 0.8427\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4079 - acc: 0.8569 - val_loss: 0.4873 - val_acc: 0.8391\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4067 - acc: 0.8564 - val_loss: 0.4679 - val_acc: 0.8410\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4072 - acc: 0.8565 - val_loss: 0.4825 - val_acc: 0.8406\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.4079 - acc: 0.8563 - val_loss: 0.4774 - val_acc: 0.8417\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.4070 - acc: 0.8572 - val_loss: 0.4686 - val_acc: 0.8415\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4031 - acc: 0.8584 - val_loss: 0.4977 - val_acc: 0.8389\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4063 - acc: 0.8575 - val_loss: 0.4738 - val_acc: 0.8406\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4061 - acc: 0.8564 - val_loss: 0.4890 - val_acc: 0.8424\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4061 - acc: 0.8575 - val_loss: 0.4943 - val_acc: 0.8422\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.4081 - acc: 0.8561 - val_loss: 0.4818 - val_acc: 0.8404\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4051 - acc: 0.8579 - val_loss: 0.4613 - val_acc: 0.8402\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4027 - acc: 0.8574 - val_loss: 0.4707 - val_acc: 0.8398\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4064 - acc: 0.8582 - val_loss: 0.4822 - val_acc: 0.8391\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4049 - acc: 0.8575 - val_loss: 0.4671 - val_acc: 0.8423\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4035 - acc: 0.8582 - val_loss: 0.4724 - val_acc: 0.8423\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4026 - acc: 0.8579 - val_loss: 0.4790 - val_acc: 0.8424\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.4037 - acc: 0.8574 - val_loss: 0.4760 - val_acc: 0.8399\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4049 - acc: 0.8566 - val_loss: 0.4676 - val_acc: 0.8404\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.4034 - acc: 0.8582 - val_loss: 0.4844 - val_acc: 0.8428\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.4043 - acc: 0.8569 - val_loss: 0.4867 - val_acc: 0.8418\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.4020 - acc: 0.8586 - val_loss: 0.4863 - val_acc: 0.8425\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.4035 - acc: 0.8582 - val_loss: 0.5237 - val_acc: 0.8368\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.4037 - acc: 0.8571 - val_loss: 0.4858 - val_acc: 0.8376\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4034 - acc: 0.8575 - val_loss: 0.4742 - val_acc: 0.8407\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4024 - acc: 0.8581 - val_loss: 0.4682 - val_acc: 0.8406\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.4025 - acc: 0.8584 - val_loss: 0.5118 - val_acc: 0.8373\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.4003 - acc: 0.8595 - val_loss: 0.5017 - val_acc: 0.8363\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.4044 - acc: 0.8577 - val_loss: 0.5001 - val_acc: 0.8372\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4013 - acc: 0.8572 - val_loss: 0.4944 - val_acc: 0.8404\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 7s 112us/sample - loss: 0.4020 - acc: 0.8583 - val_loss: 0.4756 - val_acc: 0.8408\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3997 - acc: 0.8600 - val_loss: 0.5157 - val_acc: 0.8401\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4005 - acc: 0.8583 - val_loss: 0.4737 - val_acc: 0.8415\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 7s 112us/sample - loss: 0.4020 - acc: 0.8584 - val_loss: 0.4941 - val_acc: 0.8384\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4032 - acc: 0.8573 - val_loss: 0.4894 - val_acc: 0.8387\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.4012 - acc: 0.8581 - val_loss: 0.5028 - val_acc: 0.8364\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4029 - acc: 0.8582 - val_loss: 0.4704 - val_acc: 0.8372\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.4009 - acc: 0.8583 - val_loss: 0.4768 - val_acc: 0.8397\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.4036 - acc: 0.8581 - val_loss: 0.4956 - val_acc: 0.8403\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4009 - acc: 0.8576 - val_loss: 0.4726 - val_acc: 0.8394\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4031 - acc: 0.8562 - val_loss: 0.4881 - val_acc: 0.8402\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4022 - acc: 0.8592 - val_loss: 0.4720 - val_acc: 0.8411\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4015 - acc: 0.8582 - val_loss: 0.4712 - val_acc: 0.8395\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.3993 - acc: 0.8592 - val_loss: 0.5040 - val_acc: 0.8407\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.4016 - acc: 0.8573 - val_loss: 0.4818 - val_acc: 0.8413\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3978 - acc: 0.8600 - val_loss: 0.4862 - val_acc: 0.8376\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.4001 - acc: 0.8583 - val_loss: 0.4859 - val_acc: 0.8421\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.4012 - acc: 0.8584 - val_loss: 0.4879 - val_acc: 0.8410\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.4016 - acc: 0.8571 - val_loss: 0.4763 - val_acc: 0.8394\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.4016 - acc: 0.8576 - val_loss: 0.4794 - val_acc: 0.8412\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.3994 - acc: 0.8588 - val_loss: 0.4932 - val_acc: 0.8402\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.3995 - acc: 0.8569 - val_loss: 0.4811 - val_acc: 0.8365\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4017 - acc: 0.8570 - val_loss: 0.5074 - val_acc: 0.8364\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3974 - acc: 0.8597 - val_loss: 0.4990 - val_acc: 0.8375\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.3999 - acc: 0.8588 - val_loss: 0.5204 - val_acc: 0.8343\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4002 - acc: 0.8587 - val_loss: 0.4824 - val_acc: 0.8403\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.3991 - acc: 0.8593 - val_loss: 0.4944 - val_acc: 0.8376\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3996 - acc: 0.8588 - val_loss: 0.5118 - val_acc: 0.8384\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4009 - acc: 0.8593 - val_loss: 0.4872 - val_acc: 0.8384\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3996 - acc: 0.8591 - val_loss: 0.4876 - val_acc: 0.8372\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.3954 - acc: 0.8586 - val_loss: 0.4929 - val_acc: 0.8365\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff2c0122eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwk3T5LJOIVN",
        "colab_type": "text"
      },
      "source": [
        "### Execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNLR8tcBOIVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#done above"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py-KwkmjOIVU",
        "colab_type": "text"
      },
      "source": [
        "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLXUE9jWOIVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.001)\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJUqA5T4OIVc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a9433ff-a364-4fae-b8bc-3098ad44a174"
      },
      "source": [
        "model.fit(trainX,trainY,          \n",
        "          validation_data=(testX,testY),\n",
        "          epochs=100,\n",
        "          batch_size=32)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.3990 - acc: 0.8596 - val_loss: 0.5103 - val_acc: 0.8387\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.3996 - acc: 0.8583 - val_loss: 0.4941 - val_acc: 0.8362\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.3997 - acc: 0.8578 - val_loss: 0.4864 - val_acc: 0.8421\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3979 - acc: 0.8605 - val_loss: 0.4836 - val_acc: 0.8396\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3985 - acc: 0.8600 - val_loss: 0.4918 - val_acc: 0.8348\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3993 - acc: 0.8578 - val_loss: 0.4936 - val_acc: 0.8417\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3993 - acc: 0.8587 - val_loss: 0.5020 - val_acc: 0.8350\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3978 - acc: 0.8597 - val_loss: 0.4777 - val_acc: 0.8399\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3989 - acc: 0.8580 - val_loss: 0.5258 - val_acc: 0.8403\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3981 - acc: 0.8582 - val_loss: 0.4829 - val_acc: 0.8373\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.4002 - acc: 0.8585 - val_loss: 0.4917 - val_acc: 0.8422\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3978 - acc: 0.8592 - val_loss: 0.4881 - val_acc: 0.8396\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.3994 - acc: 0.8578 - val_loss: 0.4924 - val_acc: 0.8374\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3997 - acc: 0.8580 - val_loss: 0.4704 - val_acc: 0.8426\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.3982 - acc: 0.8588 - val_loss: 0.4998 - val_acc: 0.8395\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3973 - acc: 0.8599 - val_loss: 0.4886 - val_acc: 0.8386\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.3990 - acc: 0.8584 - val_loss: 0.5151 - val_acc: 0.8393\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3990 - acc: 0.8576 - val_loss: 0.4780 - val_acc: 0.8396\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.3971 - acc: 0.8589 - val_loss: 0.4908 - val_acc: 0.8410\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.3979 - acc: 0.8595 - val_loss: 0.4863 - val_acc: 0.8360\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 7s 112us/sample - loss: 0.3989 - acc: 0.8587 - val_loss: 0.5075 - val_acc: 0.8391\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3973 - acc: 0.8597 - val_loss: 0.4915 - val_acc: 0.8415\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3966 - acc: 0.8603 - val_loss: 0.4892 - val_acc: 0.8397\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3973 - acc: 0.8586 - val_loss: 0.4997 - val_acc: 0.8369\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3978 - acc: 0.8584 - val_loss: 0.5082 - val_acc: 0.8380\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3984 - acc: 0.8585 - val_loss: 0.4977 - val_acc: 0.8389\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.3979 - acc: 0.8576 - val_loss: 0.5236 - val_acc: 0.8371\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3993 - acc: 0.8594 - val_loss: 0.4818 - val_acc: 0.8411\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3968 - acc: 0.8592 - val_loss: 0.4844 - val_acc: 0.8372\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3991 - acc: 0.8587 - val_loss: 0.4888 - val_acc: 0.8382\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3976 - acc: 0.8583 - val_loss: 0.4940 - val_acc: 0.8400\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3968 - acc: 0.8607 - val_loss: 0.4901 - val_acc: 0.8407\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.3942 - acc: 0.8610 - val_loss: 0.4892 - val_acc: 0.8353\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.3975 - acc: 0.8589 - val_loss: 0.4962 - val_acc: 0.8407\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3991 - acc: 0.8596 - val_loss: 0.4790 - val_acc: 0.8421\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3959 - acc: 0.8588 - val_loss: 0.4961 - val_acc: 0.8407\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.3958 - acc: 0.8596 - val_loss: 0.4810 - val_acc: 0.8382\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3959 - acc: 0.8592 - val_loss: 0.4807 - val_acc: 0.8408\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.3978 - acc: 0.8586 - val_loss: 0.5656 - val_acc: 0.8401\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.3979 - acc: 0.8586 - val_loss: 0.5091 - val_acc: 0.8357\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3954 - acc: 0.8594 - val_loss: 0.4845 - val_acc: 0.8408\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3984 - acc: 0.8584 - val_loss: 0.4794 - val_acc: 0.8427\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3966 - acc: 0.8605 - val_loss: 0.4783 - val_acc: 0.8404\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3975 - acc: 0.8586 - val_loss: 0.4980 - val_acc: 0.8380\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3958 - acc: 0.8587 - val_loss: 0.5004 - val_acc: 0.8391\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.3977 - acc: 0.8584 - val_loss: 0.4741 - val_acc: 0.8395\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3968 - acc: 0.8595 - val_loss: 0.4761 - val_acc: 0.8429\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3980 - acc: 0.8583 - val_loss: 0.4793 - val_acc: 0.8420\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3980 - acc: 0.8599 - val_loss: 0.4944 - val_acc: 0.8395\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3956 - acc: 0.8595 - val_loss: 0.5120 - val_acc: 0.8422\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3960 - acc: 0.8594 - val_loss: 0.4733 - val_acc: 0.8367\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.3963 - acc: 0.8604 - val_loss: 0.5057 - val_acc: 0.8367\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.3981 - acc: 0.8585 - val_loss: 0.4764 - val_acc: 0.8371\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3977 - acc: 0.8589 - val_loss: 0.4925 - val_acc: 0.8396\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3961 - acc: 0.8571 - val_loss: 0.5118 - val_acc: 0.8405\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3953 - acc: 0.8593 - val_loss: 0.4791 - val_acc: 0.8404\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3973 - acc: 0.8584 - val_loss: 0.5012 - val_acc: 0.8359\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.3961 - acc: 0.8594 - val_loss: 0.5013 - val_acc: 0.8386\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3958 - acc: 0.8585 - val_loss: 0.5133 - val_acc: 0.8402\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3985 - acc: 0.8591 - val_loss: 0.4856 - val_acc: 0.8407\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3964 - acc: 0.8604 - val_loss: 0.4876 - val_acc: 0.8410\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.3978 - acc: 0.8589 - val_loss: 0.4918 - val_acc: 0.8353\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.3947 - acc: 0.8602 - val_loss: 0.5275 - val_acc: 0.8347\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3954 - acc: 0.8600 - val_loss: 0.5031 - val_acc: 0.8405\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3958 - acc: 0.8601 - val_loss: 0.5020 - val_acc: 0.8386\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3959 - acc: 0.8589 - val_loss: 0.5045 - val_acc: 0.8387\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3941 - acc: 0.8606 - val_loss: 0.4933 - val_acc: 0.8387\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3977 - acc: 0.8580 - val_loss: 0.5295 - val_acc: 0.8381\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3947 - acc: 0.8596 - val_loss: 0.4996 - val_acc: 0.8359\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3972 - acc: 0.8582 - val_loss: 0.4921 - val_acc: 0.8405\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3966 - acc: 0.8588 - val_loss: 0.4917 - val_acc: 0.8398\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3951 - acc: 0.8601 - val_loss: 0.5415 - val_acc: 0.8401\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3961 - acc: 0.8596 - val_loss: 0.5005 - val_acc: 0.8376\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 7s 112us/sample - loss: 0.3948 - acc: 0.8589 - val_loss: 0.5063 - val_acc: 0.8397\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3956 - acc: 0.8595 - val_loss: 0.4751 - val_acc: 0.8362\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3948 - acc: 0.8594 - val_loss: 0.4913 - val_acc: 0.8363\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3956 - acc: 0.8588 - val_loss: 0.4853 - val_acc: 0.8392\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.3951 - acc: 0.8591 - val_loss: 0.4846 - val_acc: 0.8413\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.3962 - acc: 0.8591 - val_loss: 0.5162 - val_acc: 0.8404\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 7s 112us/sample - loss: 0.3990 - acc: 0.8583 - val_loss: 0.4784 - val_acc: 0.8382\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3966 - acc: 0.8593 - val_loss: 0.4816 - val_acc: 0.8394\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3950 - acc: 0.8592 - val_loss: 0.4960 - val_acc: 0.8379\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3945 - acc: 0.8608 - val_loss: 0.5293 - val_acc: 0.8385\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3957 - acc: 0.8604 - val_loss: 0.4858 - val_acc: 0.8377\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3954 - acc: 0.8605 - val_loss: 0.5427 - val_acc: 0.8386\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3933 - acc: 0.8611 - val_loss: 0.5026 - val_acc: 0.8405\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.3962 - acc: 0.8585 - val_loss: 0.4915 - val_acc: 0.8378\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3950 - acc: 0.8592 - val_loss: 0.4988 - val_acc: 0.8381\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3948 - acc: 0.8598 - val_loss: 0.5080 - val_acc: 0.8388\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3971 - acc: 0.8592 - val_loss: 0.4925 - val_acc: 0.8370\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3929 - acc: 0.8608 - val_loss: 0.5007 - val_acc: 0.8406\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3941 - acc: 0.8599 - val_loss: 0.4828 - val_acc: 0.8378\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3987 - acc: 0.8590 - val_loss: 0.5180 - val_acc: 0.8401\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3946 - acc: 0.8600 - val_loss: 0.4804 - val_acc: 0.8383\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.3960 - acc: 0.8591 - val_loss: 0.5016 - val_acc: 0.8325\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.3943 - acc: 0.8604 - val_loss: 0.5122 - val_acc: 0.8369\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3954 - acc: 0.8597 - val_loss: 0.4925 - val_acc: 0.8395\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3948 - acc: 0.8593 - val_loss: 0.4805 - val_acc: 0.8390\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3943 - acc: 0.8597 - val_loss: 0.5077 - val_acc: 0.8404\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.3952 - acc: 0.8588 - val_loss: 0.5010 - val_acc: 0.8367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff2c85494a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CSqKvpOIVk",
        "colab_type": "text"
      },
      "source": [
        "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGAad54JOIVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ7oIymROIVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0orv1DQ3fYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-O-fFxnOIVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19W6CoGs3uEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiP7IL52OIVw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "39edfb42-acf0-4e95-b292-be3d6d3d9041"
      },
      "source": [
        "model.fit(trainX,trainY,          \n",
        "          validation_data=(testX,testY),\n",
        "          epochs=100,\n",
        "          batch_size=32)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 1.5473 - acc: 0.6014 - val_loss: 1.0375 - val_acc: 0.7254\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.8688 - acc: 0.7369 - val_loss: 0.7354 - val_acc: 0.7500\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 8s 125us/sample - loss: 0.6860 - acc: 0.7641 - val_loss: 0.6285 - val_acc: 0.7776\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.6072 - acc: 0.7876 - val_loss: 0.5717 - val_acc: 0.7922\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 8s 126us/sample - loss: 0.5588 - acc: 0.8044 - val_loss: 0.5342 - val_acc: 0.8084\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.5266 - acc: 0.8155 - val_loss: 0.5088 - val_acc: 0.8179\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.5024 - acc: 0.8227 - val_loss: 0.4901 - val_acc: 0.8216\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.4850 - acc: 0.8281 - val_loss: 0.4768 - val_acc: 0.8257\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.4698 - acc: 0.8325 - val_loss: 0.4648 - val_acc: 0.8306\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.4592 - acc: 0.8365 - val_loss: 0.4552 - val_acc: 0.8356\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.4486 - acc: 0.8411 - val_loss: 0.4469 - val_acc: 0.8384\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.4390 - acc: 0.8441 - val_loss: 0.4405 - val_acc: 0.8396\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.4308 - acc: 0.8467 - val_loss: 0.4343 - val_acc: 0.8420\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.4255 - acc: 0.8484 - val_loss: 0.4289 - val_acc: 0.8448\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.4180 - acc: 0.8510 - val_loss: 0.4251 - val_acc: 0.8451\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.4111 - acc: 0.8547 - val_loss: 0.4192 - val_acc: 0.8469\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.4060 - acc: 0.8564 - val_loss: 0.4155 - val_acc: 0.8481\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.4018 - acc: 0.8563 - val_loss: 0.4115 - val_acc: 0.8499\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3969 - acc: 0.8591 - val_loss: 0.4103 - val_acc: 0.8512\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.3923 - acc: 0.8595 - val_loss: 0.4039 - val_acc: 0.8534\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.3880 - acc: 0.8612 - val_loss: 0.4019 - val_acc: 0.8547\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3855 - acc: 0.8622 - val_loss: 0.3978 - val_acc: 0.8561\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3784 - acc: 0.8648 - val_loss: 0.3937 - val_acc: 0.8580\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.3762 - acc: 0.8670 - val_loss: 0.3925 - val_acc: 0.8586\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3729 - acc: 0.8661 - val_loss: 0.3882 - val_acc: 0.8606\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3706 - acc: 0.8667 - val_loss: 0.3879 - val_acc: 0.8582\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3662 - acc: 0.8705 - val_loss: 0.3860 - val_acc: 0.8600\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.3621 - acc: 0.8703 - val_loss: 0.3819 - val_acc: 0.8608\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3613 - acc: 0.8705 - val_loss: 0.3788 - val_acc: 0.8622\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3582 - acc: 0.8722 - val_loss: 0.3772 - val_acc: 0.8634\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.3547 - acc: 0.8741 - val_loss: 0.3766 - val_acc: 0.8652\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3517 - acc: 0.8738 - val_loss: 0.3744 - val_acc: 0.8632\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3471 - acc: 0.8760 - val_loss: 0.3714 - val_acc: 0.8658\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3472 - acc: 0.8756 - val_loss: 0.3699 - val_acc: 0.8658\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.3451 - acc: 0.8766 - val_loss: 0.3683 - val_acc: 0.8659\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.3395 - acc: 0.8787 - val_loss: 0.3661 - val_acc: 0.8675\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3375 - acc: 0.8778 - val_loss: 0.3635 - val_acc: 0.8677\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.3357 - acc: 0.8808 - val_loss: 0.3639 - val_acc: 0.8680\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3333 - acc: 0.8804 - val_loss: 0.3643 - val_acc: 0.8668\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3315 - acc: 0.8812 - val_loss: 0.3609 - val_acc: 0.8681\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3291 - acc: 0.8810 - val_loss: 0.3603 - val_acc: 0.8691\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3264 - acc: 0.8831 - val_loss: 0.3559 - val_acc: 0.8719\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3248 - acc: 0.8844 - val_loss: 0.3601 - val_acc: 0.8676\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3219 - acc: 0.8842 - val_loss: 0.3544 - val_acc: 0.8708\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3189 - acc: 0.8858 - val_loss: 0.3546 - val_acc: 0.8700\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.3174 - acc: 0.8862 - val_loss: 0.3518 - val_acc: 0.8704\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.3159 - acc: 0.8863 - val_loss: 0.3519 - val_acc: 0.8719\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.3130 - acc: 0.8871 - val_loss: 0.3505 - val_acc: 0.8733\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.3118 - acc: 0.8890 - val_loss: 0.3476 - val_acc: 0.8715\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3097 - acc: 0.8888 - val_loss: 0.3472 - val_acc: 0.8733\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.3055 - acc: 0.8900 - val_loss: 0.3459 - val_acc: 0.8729\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.3047 - acc: 0.8892 - val_loss: 0.3459 - val_acc: 0.8741\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.3022 - acc: 0.8910 - val_loss: 0.3477 - val_acc: 0.8737\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.3010 - acc: 0.8911 - val_loss: 0.3441 - val_acc: 0.8745\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.2981 - acc: 0.8930 - val_loss: 0.3435 - val_acc: 0.8748\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.2968 - acc: 0.8931 - val_loss: 0.3415 - val_acc: 0.8764\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.2968 - acc: 0.8929 - val_loss: 0.3397 - val_acc: 0.8775\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.2920 - acc: 0.8950 - val_loss: 0.3413 - val_acc: 0.8761\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.2893 - acc: 0.8959 - val_loss: 0.3419 - val_acc: 0.8762\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.2890 - acc: 0.8957 - val_loss: 0.3387 - val_acc: 0.8771\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 8s 136us/sample - loss: 0.2881 - acc: 0.8967 - val_loss: 0.3370 - val_acc: 0.8777\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.2844 - acc: 0.8963 - val_loss: 0.3372 - val_acc: 0.8768\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.2838 - acc: 0.8972 - val_loss: 0.3345 - val_acc: 0.8788\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.2826 - acc: 0.8973 - val_loss: 0.3357 - val_acc: 0.8777\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.2808 - acc: 0.9001 - val_loss: 0.3365 - val_acc: 0.8794\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.2766 - acc: 0.8999 - val_loss: 0.3352 - val_acc: 0.8788\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.2762 - acc: 0.9001 - val_loss: 0.3340 - val_acc: 0.8795\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.2749 - acc: 0.8997 - val_loss: 0.3349 - val_acc: 0.8819\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.2728 - acc: 0.9020 - val_loss: 0.3373 - val_acc: 0.8792\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.2705 - acc: 0.9022 - val_loss: 0.3319 - val_acc: 0.8810\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.2703 - acc: 0.9021 - val_loss: 0.3333 - val_acc: 0.8811\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.2682 - acc: 0.9036 - val_loss: 0.3312 - val_acc: 0.8825\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.2664 - acc: 0.9039 - val_loss: 0.3297 - val_acc: 0.8806\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.2656 - acc: 0.9041 - val_loss: 0.3341 - val_acc: 0.8801\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.2647 - acc: 0.9049 - val_loss: 0.3279 - val_acc: 0.8813\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.2627 - acc: 0.9047 - val_loss: 0.3325 - val_acc: 0.8828\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.2598 - acc: 0.9069 - val_loss: 0.3267 - val_acc: 0.8836\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.2583 - acc: 0.9067 - val_loss: 0.3295 - val_acc: 0.8817\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.2569 - acc: 0.9077 - val_loss: 0.3307 - val_acc: 0.8808\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.2558 - acc: 0.9082 - val_loss: 0.3306 - val_acc: 0.8817\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.2533 - acc: 0.9082 - val_loss: 0.3306 - val_acc: 0.8796\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.2519 - acc: 0.9094 - val_loss: 0.3271 - val_acc: 0.8828\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.2509 - acc: 0.9091 - val_loss: 0.3302 - val_acc: 0.8825\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.2476 - acc: 0.9101 - val_loss: 0.3308 - val_acc: 0.8810\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.2475 - acc: 0.9106 - val_loss: 0.3286 - val_acc: 0.8826\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.2467 - acc: 0.9108 - val_loss: 0.3265 - val_acc: 0.8832\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.2454 - acc: 0.9129 - val_loss: 0.3267 - val_acc: 0.8833\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.2416 - acc: 0.9134 - val_loss: 0.3312 - val_acc: 0.8826\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.2410 - acc: 0.9129 - val_loss: 0.3267 - val_acc: 0.8829\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.2395 - acc: 0.9142 - val_loss: 0.3273 - val_acc: 0.8833\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.2385 - acc: 0.9143 - val_loss: 0.3274 - val_acc: 0.8849\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.2377 - acc: 0.9146 - val_loss: 0.3263 - val_acc: 0.8827\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.2353 - acc: 0.9160 - val_loss: 0.3300 - val_acc: 0.8844\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.2355 - acc: 0.9151 - val_loss: 0.3273 - val_acc: 0.8840\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.2331 - acc: 0.9159 - val_loss: 0.3295 - val_acc: 0.8833\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.2314 - acc: 0.9154 - val_loss: 0.3304 - val_acc: 0.8835\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.2285 - acc: 0.9175 - val_loss: 0.3262 - val_acc: 0.8848\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.2288 - acc: 0.9175 - val_loss: 0.3265 - val_acc: 0.8853\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.2274 - acc: 0.9176 - val_loss: 0.3330 - val_acc: 0.8854\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.2282 - acc: 0.9178 - val_loss: 0.3305 - val_acc: 0.8857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff279a24fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr2YsZV0OIV0",
        "colab_type": "text"
      },
      "source": [
        "## Review model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ojW6-oOIV2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "94e40006-b6df-44d4-b05b-c8856bf30ca8"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_2 (Reshape)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 92,746\n",
            "Trainable params: 91,178\n",
            "Non-trainable params: 1,568\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfFGmbZLOIV5",
        "colab_type": "text"
      },
      "source": [
        "### Run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIkbMEN5OIV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('mnist_fashion_v1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MrgWMY4vZAk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "fa145fba-6775-4348-fd04-c1f549c963e5"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 392\n",
            "-rw-r--r-- 1 root root 395320 Nov  5 08:45 mnist_fashion_v1.h5\n",
            "drwxr-xr-x 1 root root   4096 Oct 25 16:58 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Uy4cnUrvuzp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "4a8b7082-cfa3-4720-f668-754d52ef7a9a"
      },
      "source": [
        "model = tf.keras.models.load_model('mnist_fashion_v1.h5')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxwCcWnGv37K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "680e0841-551a-48bf-d098-d10b793b1570"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_2 (Reshape)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 92,746\n",
            "Trainable params: 91,178\n",
            "Non-trainable params: 1,568\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K9khhIBv_oE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d4e2a1b2-9dbc-4811-e005-04e69499480d"
      },
      "source": [
        "model.input"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'reshape_2_input_1:0' shape=(?, 28, 28) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrV39rw9wGc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "83ffd14d-d6ba-48cc-d36c-c08bc2257b83"
      },
      "source": [
        "testX[0:5].shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6OjUguPwPha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8TDpAUkwfeM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "88e51964-66fa-4eb6-e23b-b492ca933207"
      },
      "source": [
        "input_data = np.expand_dims(testX[0], axis=0)\n",
        "input_data.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ItX3aZ4wmfJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d3688d41-2b24-423f-c9e5-dd14826cfecd"
      },
      "source": [
        "pred = model.predict(input_data)\n",
        "#pred\n",
        "print(pred)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.2870645e-05 3.0628680e-06 6.5266853e-05 9.3979332e-05 3.2867600e-05\n",
            "  1.3424925e-03 5.7134149e-04 1.0755649e-02 1.6148557e-04 9.8696089e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}